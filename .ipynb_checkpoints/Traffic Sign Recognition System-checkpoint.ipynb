{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPool2D,Dense,Flatten,Dropout\n",
    "from keras.utils import to_categorical\n",
    "from PIL import Image\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seggregate the images into array along with their folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Folders = []\n",
    "Images  = []\n",
    "total_sign = 43\n",
    "\n",
    "path = os.getcwd()\n",
    "\n",
    "for i in range(total_sign):\n",
    "    subfoldr_path = os.path.join(path,'train',str(i))\n",
    "    images        = os.listdir(subfoldr_path)\n",
    "    \n",
    "    for j in (images):\n",
    "        try:\n",
    "            image = Image.open(subfoldr_path+'\\\\'+j)\n",
    "            image = image.resize((30,30))\n",
    "            image = np.array(image)\n",
    "            Images.append(image)\n",
    "            Folders.append(i)\n",
    "        except:\n",
    "            print(\"Error loading image\")\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting into array and printing the images and their folders in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Images = np.array(Images)\n",
    "Folders = np.array(Folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 75  78  80]\n",
      "   [ 74  76  78]\n",
      "   [ 85  86  84]\n",
      "   ...\n",
      "   [ 68  75  74]\n",
      "   [ 65  69  68]\n",
      "   [ 66  67  66]]\n",
      "\n",
      "  [[ 83  84  86]\n",
      "   [ 80  80  82]\n",
      "   [ 88  88  83]\n",
      "   ...\n",
      "   [ 73  77  78]\n",
      "   [ 76  78  75]\n",
      "   [ 80  80  78]]\n",
      "\n",
      "  [[ 78  78  80]\n",
      "   [ 86  85  86]\n",
      "   [ 90  89  90]\n",
      "   ...\n",
      "   [ 71  74  71]\n",
      "   [ 73  74  69]\n",
      "   [ 78  78  74]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[133 134 139]\n",
      "   [123 127 132]\n",
      "   [112 121 125]\n",
      "   ...\n",
      "   [ 94  95  89]\n",
      "   [ 97  98  91]\n",
      "   [ 99 103  99]]\n",
      "\n",
      "  [[ 91  95  99]\n",
      "   [ 91  98 103]\n",
      "   [ 75  86  90]\n",
      "   ...\n",
      "   [104 102  96]\n",
      "   [110 113 104]\n",
      "   [ 96 104  98]]\n",
      "\n",
      "  [[ 85  84  87]\n",
      "   [ 95 101 107]\n",
      "   [ 63  76  81]\n",
      "   ...\n",
      "   [103 103  95]\n",
      "   [ 99 102  90]\n",
      "   [ 90  97  89]]]\n",
      "\n",
      "\n",
      " [[[ 69  73  73]\n",
      "   [ 76  79  79]\n",
      "   [ 75  77  77]\n",
      "   ...\n",
      "   [ 76  81  80]\n",
      "   [ 71  77  77]\n",
      "   [ 66  68  70]]\n",
      "\n",
      "  [[ 65  69  69]\n",
      "   [ 74  76  76]\n",
      "   [ 84  84  83]\n",
      "   ...\n",
      "   [ 90  83  89]\n",
      "   [ 74  79  84]\n",
      "   [ 67  69  73]]\n",
      "\n",
      "  [[ 63  68  68]\n",
      "   [ 71  72  72]\n",
      "   [ 81  79  77]\n",
      "   ...\n",
      "   [105  86  91]\n",
      "   [ 71  75  76]\n",
      "   [ 69  71  69]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[164 139 142]\n",
      "   [157 139 144]\n",
      "   [151 139 143]\n",
      "   ...\n",
      "   [ 76  77  79]\n",
      "   [ 77  80  76]\n",
      "   [ 90  93  82]]\n",
      "\n",
      "  [[102 103 104]\n",
      "   [103 102 104]\n",
      "   [101  97 103]\n",
      "   ...\n",
      "   [ 80  81  82]\n",
      "   [ 92  95  91]\n",
      "   [106 110 101]]\n",
      "\n",
      "  [[ 72  74  74]\n",
      "   [ 82  83  82]\n",
      "   [ 92  92  99]\n",
      "   ...\n",
      "   [ 74  74  75]\n",
      "   [103 103 100]\n",
      "   [101 104  96]]]\n",
      "\n",
      "\n",
      " [[[ 72  72  72]\n",
      "   [ 79  79  79]\n",
      "   [ 78  78  73]\n",
      "   ...\n",
      "   [ 78  81  71]\n",
      "   [ 72  79  73]\n",
      "   [ 63  66  64]]\n",
      "\n",
      "  [[ 66  68  68]\n",
      "   [ 77  75  74]\n",
      "   [ 94  87  86]\n",
      "   ...\n",
      "   [108  93  87]\n",
      "   [ 77  80  77]\n",
      "   [ 74  75  74]]\n",
      "\n",
      "  [[ 65  69  69]\n",
      "   [ 76  71  71]\n",
      "   [112  98 101]\n",
      "   ...\n",
      "   [120  87  91]\n",
      "   [ 74  74  74]\n",
      "   [ 69  69  67]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[146 133 117]\n",
      "   [143 130 114]\n",
      "   [140 127 119]\n",
      "   ...\n",
      "   [ 75  76  75]\n",
      "   [ 72  75  75]\n",
      "   [ 73  76  77]]\n",
      "\n",
      "  [[114 121 113]\n",
      "   [115 116 107]\n",
      "   [115 111 107]\n",
      "   ...\n",
      "   [ 71  73  73]\n",
      "   [ 79  81  80]\n",
      "   [ 92  94  92]]\n",
      "\n",
      "  [[ 73  78  77]\n",
      "   [ 84  87  84]\n",
      "   [ 95  96  95]\n",
      "   ...\n",
      "   [ 70  71  71]\n",
      "   [ 81  82  79]\n",
      "   [ 95  97  91]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 11  11  13]\n",
      "   [ 12  12  14]\n",
      "   [ 13  11  13]\n",
      "   ...\n",
      "   [ 12  11  13]\n",
      "   [ 12  11  13]\n",
      "   [ 12  10  13]]\n",
      "\n",
      "  [[ 11  11  14]\n",
      "   [ 13  11  14]\n",
      "   [ 12  11  13]\n",
      "   ...\n",
      "   [ 12  11  13]\n",
      "   [ 12  12  13]\n",
      "   [ 12  11  12]]\n",
      "\n",
      "  [[  9  10  13]\n",
      "   [ 12  12  16]\n",
      "   [ 14  15  17]\n",
      "   ...\n",
      "   [ 11  11  13]\n",
      "   [ 11  11  13]\n",
      "   [ 11  11  11]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 10  10  12]\n",
      "   [ 10   9  11]\n",
      "   [  9   9  11]\n",
      "   ...\n",
      "   [ 10   9  12]\n",
      "   [ 11  10  12]\n",
      "   [ 11  11  12]]\n",
      "\n",
      "  [[ 10   9  12]\n",
      "   [ 10   9  11]\n",
      "   [ 10   9  11]\n",
      "   ...\n",
      "   [ 11   9  12]\n",
      "   [ 10  11  13]\n",
      "   [ 12  11  12]]\n",
      "\n",
      "  [[ 10   9  12]\n",
      "   [ 11  10  12]\n",
      "   [ 10   9  11]\n",
      "   ...\n",
      "   [ 11  10  11]\n",
      "   [ 11  11  13]\n",
      "   [ 12  11  13]]]\n",
      "\n",
      "\n",
      " [[[ 13  13  15]\n",
      "   [ 14  13  16]\n",
      "   [ 13  11  13]\n",
      "   ...\n",
      "   [ 12  11  12]\n",
      "   [ 11  10  11]\n",
      "   [ 11  13  19]]\n",
      "\n",
      "  [[ 14  12  14]\n",
      "   [ 13  12  14]\n",
      "   [ 14  12  14]\n",
      "   ...\n",
      "   [ 11  11  13]\n",
      "   [ 11  10  12]\n",
      "   [ 10  11  14]]\n",
      "\n",
      "  [[ 12  11  12]\n",
      "   [ 13  12  13]\n",
      "   [ 13  12  14]\n",
      "   ...\n",
      "   [ 11  10  12]\n",
      "   [ 11  10  12]\n",
      "   [ 10   9  11]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 12  12  13]\n",
      "   [ 11  10  11]\n",
      "   [  9   9  11]\n",
      "   ...\n",
      "   [ 13  12  13]\n",
      "   [ 11   9  11]\n",
      "   [  9   9  10]]\n",
      "\n",
      "  [[ 11  10  12]\n",
      "   [ 12  10  12]\n",
      "   [ 10   9  11]\n",
      "   ...\n",
      "   [ 14  13  15]\n",
      "   [ 11  10  10]\n",
      "   [ 10   9   9]]\n",
      "\n",
      "  [[ 10   9  11]\n",
      "   [ 10   9  11]\n",
      "   [ 10  10  12]\n",
      "   ...\n",
      "   [ 14  12  14]\n",
      "   [ 11  10  11]\n",
      "   [ 10   9  10]]]\n",
      "\n",
      "\n",
      " [[[ 11  10  12]\n",
      "   [ 11  10  11]\n",
      "   [ 10  10  11]\n",
      "   ...\n",
      "   [ 18  20  22]\n",
      "   [ 25  24  23]\n",
      "   [ 24  17  17]]\n",
      "\n",
      "  [[ 12  11  12]\n",
      "   [ 12  11  12]\n",
      "   [ 12  10  12]\n",
      "   ...\n",
      "   [ 45  60  77]\n",
      "   [ 80  77  83]\n",
      "   [ 51  30  27]]\n",
      "\n",
      "  [[ 12  12  13]\n",
      "   [ 12  12  14]\n",
      "   [ 12  11  12]\n",
      "   ...\n",
      "   [ 69  87 109]\n",
      "   [ 89  84 103]\n",
      "   [ 51  38  44]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 12  11  14]\n",
      "   [ 13  11  12]\n",
      "   [ 10   9  10]\n",
      "   ...\n",
      "   [ 10   9  11]\n",
      "   [ 10   9  11]\n",
      "   [  9   9  11]]\n",
      "\n",
      "  [[ 11  11  13]\n",
      "   [ 11  10  12]\n",
      "   [  9   9  10]\n",
      "   ...\n",
      "   [ 10   9  11]\n",
      "   [  9   9  11]\n",
      "   [ 10   9  11]]\n",
      "\n",
      "  [[ 11  11  12]\n",
      "   [ 10  10  11]\n",
      "   [  9   9  10]\n",
      "   ...\n",
      "   [ 10   9  12]\n",
      "   [ 10  10  11]\n",
      "   [ 10   9  11]]]]\n"
     ]
    }
   ],
   "source": [
    "print(Images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0 ... 42 42 42]\n"
     ]
    }
   ],
   "source": [
    "print(Folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39209, 30, 30, 3)\n"
     ]
    }
   ],
   "source": [
    "print(Images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting into training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(Images,Folders,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting the Folders which are outputs into one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = to_categorical(Y_train,43)\n",
    "Y_test  = to_categorical(Y_test,43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32,kernel_size=(5,5),activation='relu',input_shape=X_train.shape[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add a second convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=32,kernel_size=(5,5),activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(rate=0.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Adding a third convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=64,kernel_size=(3,3),activation='relu'))\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flatening the model into a neural network consisting of input nodes anfd generate the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(43, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 31367 samples, validate on 7842 samples\n",
      "Epoch 1/25\n",
      "31367/31367 [==============================] - 157s 5ms/step - loss: 2.1052 - accuracy: 0.4688 - val_loss: 0.5975 - val_accuracy: 0.8388\n",
      "Epoch 2/25\n",
      "31367/31367 [==============================] - 152s 5ms/step - loss: 0.7245 - accuracy: 0.7877 - val_loss: 0.2487 - val_accuracy: 0.9320\n",
      "Epoch 3/25\n",
      "31367/31367 [==============================] - 153s 5ms/step - loss: 0.4727 - accuracy: 0.8616 - val_loss: 0.1196 - val_accuracy: 0.9637\n",
      "Epoch 4/25\n",
      "31367/31367 [==============================] - 153s 5ms/step - loss: 0.3402 - accuracy: 0.9027 - val_loss: 0.0995 - val_accuracy: 0.9735\n",
      "Epoch 5/25\n",
      "31367/31367 [==============================] - 153s 5ms/step - loss: 0.3196 - accuracy: 0.9107 - val_loss: 0.1085 - val_accuracy: 0.9702\n",
      "Epoch 6/25\n",
      "31367/31367 [==============================] - 153s 5ms/step - loss: 0.2741 - accuracy: 0.9251 - val_loss: 0.0653 - val_accuracy: 0.9858\n",
      "Epoch 7/25\n",
      "31367/31367 [==============================] - 154s 5ms/step - loss: 0.2461 - accuracy: 0.9315 - val_loss: 0.0829 - val_accuracy: 0.9784\n",
      "Epoch 8/25\n",
      "31367/31367 [==============================] - 153s 5ms/step - loss: 0.2375 - accuracy: 0.9370 - val_loss: 0.0547 - val_accuracy: 0.9850\n",
      "Epoch 9/25\n",
      "31367/31367 [==============================] - 154s 5ms/step - loss: 0.2418 - accuracy: 0.9371 - val_loss: 0.0501 - val_accuracy: 0.9867\n",
      "Epoch 10/25\n",
      "31367/31367 [==============================] - 154s 5ms/step - loss: 0.2492 - accuracy: 0.9376 - val_loss: 0.0718 - val_accuracy: 0.9810\n",
      "Epoch 11/25\n",
      "31367/31367 [==============================] - 155s 5ms/step - loss: 0.2217 - accuracy: 0.9441 - val_loss: 0.0813 - val_accuracy: 0.9788\n",
      "Epoch 12/25\n",
      "31367/31367 [==============================] - 158s 5ms/step - loss: 0.2294 - accuracy: 0.9428 - val_loss: 0.0653 - val_accuracy: 0.9816\n",
      "Epoch 13/25\n",
      "31367/31367 [==============================] - 160s 5ms/step - loss: 0.2545 - accuracy: 0.9375 - val_loss: 0.0490 - val_accuracy: 0.9889\n",
      "Epoch 14/25\n",
      "31367/31367 [==============================] - 188s 6ms/step - loss: 0.2014 - accuracy: 0.9490 - val_loss: 0.0595 - val_accuracy: 0.9862\n",
      "Epoch 15/25\n",
      "31367/31367 [==============================] - 199s 6ms/step - loss: 0.2607 - accuracy: 0.9398 - val_loss: 0.0798 - val_accuracy: 0.9787\n",
      "Epoch 16/25\n",
      "31367/31367 [==============================] - 173s 6ms/step - loss: 0.2230 - accuracy: 0.9471 - val_loss: 0.0681 - val_accuracy: 0.9828\n",
      "Epoch 17/25\n",
      "31367/31367 [==============================] - 172s 5ms/step - loss: 0.2263 - accuracy: 0.9472 - val_loss: 0.0413 - val_accuracy: 0.9902\n",
      "Epoch 18/25\n",
      "31367/31367 [==============================] - 175s 6ms/step - loss: 0.2114 - accuracy: 0.9504 - val_loss: 0.1042 - val_accuracy: 0.9684\n",
      "Epoch 19/25\n",
      "31367/31367 [==============================] - 172s 5ms/step - loss: 0.2380 - accuracy: 0.9461 - val_loss: 0.0987 - val_accuracy: 0.9737\n",
      "Epoch 20/25\n",
      "31367/31367 [==============================] - 169s 5ms/step - loss: 0.2685 - accuracy: 0.9411 - val_loss: 0.0659 - val_accuracy: 0.9839\n",
      "Epoch 21/25\n",
      "31367/31367 [==============================] - 168s 5ms/step - loss: 0.2158 - accuracy: 0.9523 - val_loss: 0.0504 - val_accuracy: 0.9893\n",
      "Epoch 22/25\n",
      "31367/31367 [==============================] - 169s 5ms/step - loss: 0.2476 - accuracy: 0.9454 - val_loss: 0.0697 - val_accuracy: 0.9841\n",
      "Epoch 23/25\n",
      "31367/31367 [==============================] - 169s 5ms/step - loss: 0.2526 - accuracy: 0.9439 - val_loss: 0.0539 - val_accuracy: 0.9867\n",
      "Epoch 24/25\n",
      "31367/31367 [==============================] - 179s 6ms/step - loss: 0.2232 - accuracy: 0.9470 - val_loss: 0.0408 - val_accuracy: 0.9892\n",
      "Epoch 25/25\n",
      "31367/31367 [==============================] - 184s 6ms/step - loss: 0.2202 - accuracy: 0.9521 - val_loss: 0.0684 - val_accuracy: 0.9825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x14565be4308>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch = 25\n",
    "\n",
    "model.fit(X_train,Y_train,batch_size=32,epochs=epoch,validation_data=(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation of model against a test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9857430691932975"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "Y_test = pd.read_csv('Train.csv')\n",
    "\n",
    "Folders   = Y_test['ClassId'].values\n",
    "Images  = Y_test['Path'].values\n",
    "\n",
    "data = []\n",
    "\n",
    "for img in Images:\n",
    "    image = Image.open(img)\n",
    "    image = image.resize((30,30))\n",
    "    data.append(np.array(image))\n",
    "\n",
    "X_test = np.array(data)\n",
    "\n",
    "pred = model.predict_classes(X_test)\n",
    "\n",
    "accuracy_score(Folders,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model in classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('traffic_classifier.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
